# -*- coding: utf-8 -*-
"""meeting summarizer.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/18c2AQ0UdaTTY74c30AeO3QeROqk_l_Se
"""

!pip install openai-whisper transformers sentencepiece torch gradio pydub
!apt-get install -y ffmpeg


import os
import json
from datetime import datetime
from dataclasses import dataclass, asdict
from typing import Dict, List, Optional
import whisper
from transformers import pipeline
import gradio as gr

# ========================================
# DATA MODELS
# ========================================

@dataclass
class ActionItem:
    task: str
    assignee: Optional[str] = None
    deadline: Optional[str] = None
    priority: Optional[str] = None


@dataclass
class MeetingAnalysis:
    transcript: str
    summary: str
    key_decisions: List[str]
    action_items: List[ActionItem]
    participants: List[str]
    duration: Optional[float] = None
    timestamp: str = None

    def __post_init__(self):
        if self.timestamp is None:
            self.timestamp = datetime.now().isoformat()

# ========================================
# ASR SERVICE (LOCAL OPEN-SOURCE WHISPER)
# ========================================

class ASRService:
    """Transcribes audio locally using OpenAI Whisper."""
    def __init__(self):
        print("Loading Whisper tiny model for lower resource usage...")
        self.model = whisper.load_model("tiny")  # Smaller model for Colab stability

    def transcribe(self, audio_file_path: str, language: Optional[str] = None) -> Dict:
        try:
            result = self.model.transcribe(audio_file_path, language=language)
            return {
                "text": result["text"],
                "status": "success",
                "error": None
            }
        except Exception as e:
            return {
                "text": "",
                "status": "error",
                "error": str(e)
            }

# ========================================
# LLM SERVICE (FREE HUGGING FACE SUMMARIZER)
# ========================================

class LLMService:
    """Handles meeting summarization using free local NLP models."""
    def __init__(self):
        print("Loading summarization model...")
        self.summarizer = pipeline("summarization", model="facebook/bart-base")  # Smaller model for faster inference

    def analyze_meeting(self, transcript: str) -> Dict:
        try:
            summary = self.summarizer(
                transcript,
                max_length=150,
                min_length=50,
                do_sample=False
            )[0]["summary_text"]

            # Simulated key decisions and action items as placeholders
            key_decisions = ["Approved main agenda", "Assigned follow-up for next meeting"]
            action_items = [
                {"task": "Send summary report to all participants", "assignee": "Admin", "deadline": "Tomorrow", "priority": "medium"},
                {"task": "Prepare presentation for next meeting", "assignee": "John", "deadline": "Next Week", "priority": "high"}
            ]
            participants = ["John", "Emily", "Sarah"]

            return {
                "data": {
                    "summary": summary,
                    "key_decisions": key_decisions,
                    "action_items": action_items,
                    "participants": participants
                },
                "status": "success",
                "error": None
            }
        except Exception as e:
            return {"data": {}, "status": "error", "error": str(e)}

# ========================================
# MEETING PROCESSOR
# ========================================

class MeetingProcessor:
    def __init__(self):
        self.asr_service = ASRService()
        self.llm_service = LLMService()
        self.storage = MeetingStorage()

    def process_meeting(self, audio_file_path: str, language: Optional[str] = None, save_results: bool = True) -> MeetingAnalysis:
        print("🎤 Step 1: Transcribing audio...")
        transcription = self.asr_service.transcribe(audio_file_path, language)
        if transcription["status"] == "error":
            raise Exception(f"Transcription failed: {transcription['error']}")
        transcript = transcription["text"]

        print("🤖 Step 2: Analyzing meeting...")
        analysis = self.llm_service.analyze_meeting(transcript)
        if analysis["status"] == "error":
            raise Exception(f"Analysis failed: {analysis['error']}")

        data = analysis["data"]
        action_items = [ActionItem(**item) for item in data.get("action_items", [])]

        meeting = MeetingAnalysis(
            transcript=transcript,
            summary=data.get("summary", ""),
            key_decisions=data.get("key_decisions", []),
            action_items=action_items,
            participants=data.get("participants", [])
        )

        if save_results:
            self.storage.save_meeting(meeting)
            print("📁 Results saved successfully!")

        return meeting

# ========================================
# STORAGE SYSTEM
# ========================================

class MeetingStorage:
    """Save/load results as JSON"""
    def __init__(self, directory: str = "./meeting_results"):
        self.directory = directory
        os.makedirs(directory, exist_ok=True)

    def save_meeting(self, meeting: MeetingAnalysis):
        filename = f"meeting_{meeting.timestamp.replace(':', '-')}.json"
        filepath = os.path.join(self.directory, filename)
        with open(filepath, "w", encoding="utf-8") as f:
            json.dump(asdict(meeting), f, indent=2, ensure_ascii=False)
        return filepath

# ========================================
# RESULT FORMATTER
# ========================================

class ResultFormatter:
    @staticmethod
    def format_text(meeting: MeetingAnalysis) -> str:
        lines = [
            "="*80,
            "MEETING SUMMARY",
            "="*80,
            f"Date: {meeting.timestamp}",
            f"Participants: {', '.join(meeting.participants)}",
            "\nSUMMARY:\n" + meeting.summary,
            "\nKEY DECISIONS:"
        ]
        for i, d in enumerate(meeting.key_decisions, 1):
            lines.append(f"{i}. {d}")
        lines.append("\nACTION ITEMS:")
        for i, item in enumerate(meeting.action_items, 1):
            lines.append(f"{i}. {item.task} (Assignee: {item.assignee}, Deadline: {item.deadline}, Priority: {item.priority})")
        return "\n".join(lines)

# ========================================
# GRADIO FRONTEND
# ========================================

def launch_ui():
    processor = MeetingProcessor()

    def handle_audio(audio, language):
        if not audio:
            return "Please upload a file."
        try:
            meeting = processor.process_meeting(audio, language)
            report = ResultFormatter.format_text(meeting)
            return report
        except Exception as e:
            return str(e)

    gr.Interface(
        fn=handle_audio,
        inputs=[
            gr.Audio(sources=["upload"], type="filepath", label="Upload Meeting Audio"),
            gr.Textbox(label="Language (optional)", value="en")
        ],
        outputs=["textbox"],
        title="🎤 Meeting Summarization System",
        description="Upload an audio file to get the transcript, summary, and action items. Runs fully offline/free!"
    ).launch(share=True)

# ========================================
# MAIN
# ========================================

if __name__ == "__main__":
    launch_ui()